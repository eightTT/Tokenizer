{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPls0hyq8HJpQ0JZQVGISj6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eightTT/Tokenizer/blob/main/Tokenizer_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this step test the converting text to raw byte\\\n",
        "this is the naive way to convert human language to language that machine can understand\\\n",
        "in the most naive way, we can continue with this and build a 'vocabulary', but\\\n",
        "this way has 2 big drawbacks: cost too much memory + bad for sematic prediction\\\n",
        "so\\\n",
        "we do smth like BytePairEncoding: encode text by Pair so we can shrink the qualitymemory cost and still keep the semantic quality\\\n",
        "so\\\n",
        "we train our Tokenizer on BPE algo. and this step is Separate from LLM training. this step is called Pre-processing stuff.\n"
      ],
      "metadata": {
        "id": "CXngJ2MwRScZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I8kWlsTf8Fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830b7523-8c75-4274-bce2-cc91365aa946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "In the Symposium, Eros is recognized both as erotic lover and as a phenomenon capable of inspiring courage, valor, great deeds and works, and vanquishing man's natural fear of death. It is seen as transcending its earthly origins and attaining spiritual heights. The extraordinary elevation of the concept of love raises a question of whether some of the most extreme extents of meaning might be intended as humor or farce. Eros is almost always translated as \"love,\" and the English word has its own varieties and ambiguities that provide additional challenges to the effort to understand the Eros of ancient Athens.\n",
            "617\n",
            "---\n",
            "[73, 110, 32, 116, 104, 101, 32, 83, 121, 109, 112, 111, 115, 105, 117, 109, 44, 32, 69, 114, 111, 115, 32, 105, 115, 32, 114, 101, 99, 111, 103, 110, 105, 122, 101, 100, 32, 98, 111, 116, 104, 32, 97, 115, 32, 101, 114, 111, 116, 105, 99, 32, 108, 111, 118, 101, 114, 32, 97, 110, 100, 32, 97, 115, 32, 97, 32, 112, 104, 101, 110, 111, 109, 101, 110, 111, 110, 32, 99, 97, 112, 97, 98, 108, 101, 32, 111, 102, 32, 105, 110, 115, 112, 105, 114, 105, 110, 103, 32, 99, 111, 117, 114, 97, 103, 101, 44, 32, 118, 97, 108, 111, 114, 44, 32, 103, 114, 101, 97, 116, 32, 100, 101, 101, 100, 115, 32, 97, 110, 100, 32, 119, 111, 114, 107, 115, 44, 32, 97, 110, 100, 32, 118, 97, 110, 113, 117, 105, 115, 104, 105, 110, 103, 32, 109, 97, 110, 39, 115, 32, 110, 97, 116, 117, 114, 97, 108, 32, 102, 101, 97, 114, 32, 111, 102, 32, 100, 101, 97, 116, 104, 46, 32, 73, 116, 32, 105, 115, 32, 115, 101, 101, 110, 32, 97, 115, 32, 116, 114, 97, 110, 115, 99, 101, 110, 100, 105, 110, 103, 32, 105, 116, 115, 32, 101, 97, 114, 116, 104, 108, 121, 32, 111, 114, 105, 103, 105, 110, 115, 32, 97, 110, 100, 32, 97, 116, 116, 97, 105, 110, 105, 110, 103, 32, 115, 112, 105, 114, 105, 116, 117, 97, 108, 32, 104, 101, 105, 103, 104, 116, 115, 46, 32, 84, 104, 101, 32, 101, 120, 116, 114, 97, 111, 114, 100, 105, 110, 97, 114, 121, 32, 101, 108, 101, 118, 97, 116, 105, 111, 110, 32, 111, 102, 32, 116, 104, 101, 32, 99, 111, 110, 99, 101, 112, 116, 32, 111, 102, 32, 108, 111, 118, 101, 32, 114, 97, 105, 115, 101, 115, 32, 97, 32, 113, 117, 101, 115, 116, 105, 111, 110, 32, 111, 102, 32, 119, 104, 101, 116, 104, 101, 114, 32, 115, 111, 109, 101, 32, 111, 102, 32, 116, 104, 101, 32, 109, 111, 115, 116, 32, 101, 120, 116, 114, 101, 109, 101, 32, 101, 120, 116, 101, 110, 116, 115, 32, 111, 102, 32, 109, 101, 97, 110, 105, 110, 103, 32, 109, 105, 103, 104, 116, 32, 98, 101, 32, 105, 110, 116, 101, 110, 100, 101, 100, 32, 97, 115, 32, 104, 117, 109, 111, 114, 32, 111, 114, 32, 102, 97, 114, 99, 101, 46, 32, 69, 114, 111, 115, 32, 105, 115, 32, 97, 108, 109, 111, 115, 116, 32, 97, 108, 119, 97, 121, 115, 32, 116, 114, 97, 110, 115, 108, 97, 116, 101, 100, 32, 97, 115, 32, 34, 108, 111, 118, 101, 44, 34, 32, 97, 110, 100, 32, 116, 104, 101, 32, 69, 110, 103, 108, 105, 115, 104, 32, 119, 111, 114, 100, 32, 104, 97, 115, 32, 105, 116, 115, 32, 111, 119, 110, 32, 118, 97, 114, 105, 101, 116, 105, 101, 115, 32, 97, 110, 100, 32, 97, 109, 98, 105, 103, 117, 105, 116, 105, 101, 115, 32, 116, 104, 97, 116, 32, 112, 114, 111, 118, 105, 100, 101, 32, 97, 100, 100, 105, 116, 105, 111, 110, 97, 108, 32, 99, 104, 97, 108, 108, 101, 110, 103, 101, 115, 32, 116, 111, 32, 116, 104, 101, 32, 101, 102, 102, 111, 114, 116, 32, 116, 111, 32, 117, 110, 100, 101, 114, 115, 116, 97, 110, 100, 32, 116, 104, 101, 32, 69, 114, 111, 115, 32, 111, 102, 32, 97, 110, 99, 105, 101, 110, 116, 32, 65, 116, 104, 101, 110, 115, 46]\n",
            "617\n"
          ]
        }
      ],
      "source": [
        "# source = \"https://en.wikipedia.org/wiki/Symposium_(Plato)\"\n",
        "text = \"In the Symposium, Eros is recognized both as erotic lover and as a phenomenon capable of inspiring courage, valor, great deeds and works, and vanquishing man's natural fear of death. It is seen as transcending its earthly origins and attaining spiritual heights. The extraordinary elevation of the concept of love raises a question of whether some of the most extreme extents of meaning might be intended as humor or farce. Eros is almost always translated as \\\"love,\\\" and the English word has its own varieties and ambiguities that provide additional challenges to the effort to understand the Eros of ancient Athens.\"\n",
        "tokens = text.encode(\"utf-8\") #raw bytes\n",
        "tokens = list(map(int, tokens)) #map integer value for bytes\n",
        "print('---')\n",
        "print(text)\n",
        "print(len(text))\n",
        "print('---')\n",
        "print(tokens)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byte Pair Encoding (BPE)"
      ],
      "metadata": {
        "id": "0QPJvnbciFfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_common_pair(ids:list):\n",
        "  '''\n",
        "  the function that find the most common pair in the text corpus,\n",
        "  read the list of ids,\n",
        "  create (a dictionary of) pair of byte,\n",
        "  count to keep tract of total number (not neccesary),\n",
        "  return dictionary\n",
        "  '''\n",
        "  counts = {}\n",
        "  for pair in zip(ids, ids[1:]):\n",
        "    counts[pair] = counts.get(pair, 0) + 1\n",
        "  return counts\n",
        "\n",
        "stats = get_common_pair(tokens)\n",
        "# print(stats)\n",
        "# print(sorted(( (v,k) for k, v in stats.items()), reverse=True))"
      ],
      "metadata": {
        "id": "egWN8qPqkIZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chr(115),chr(32),chr(97),chr(110)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTrcq9Uoo8Cb",
        "outputId": "42354296-92f7-4675-9636-93e22e1c0c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('s', ' ', 'a', 'n')"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_pair = max(stats, key=stats.get)\n",
        "top_pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DberzRVvrT95",
        "outputId": "42540a5a-f1e5-4d12-9d23-b56482804814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the initial tokens have the ids from 0-255\\\n",
        "for new tokens (the pair), assign id = 256\n",
        "and so on"
      ],
      "metadata": {
        "id": "MifAm_kqqIbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_new_token_with_new_id(ids, pair, idx):\n",
        "  '''\n",
        "  get the list of id (ids)\n",
        "  the maximum pair from the ids (pair)\n",
        "  repalce by a new index (idx)\n",
        "  '''\n",
        "  new_ids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids)-1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      new_ids.append(idx)\n",
        "      i+=2\n",
        "    else:\n",
        "      new_ids.append(ids[i])\n",
        "      i+=1\n",
        "  return new_ids\n",
        "\n",
        "token2 = map_new_token_with_new_id(tokens, top_pair, 256)\n",
        "print(token2)\n",
        "print(len(token2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6R00gInqnUe",
        "outputId": "5113348a-cfe9-42c4-8aed-30a60fbed993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[73, 110, 32, 116, 104, 101, 32, 83, 121, 109, 112, 111, 115, 105, 117, 109, 44, 32, 69, 114, 111, 256, 105, 256, 114, 101, 99, 111, 103, 110, 105, 122, 101, 100, 32, 98, 111, 116, 104, 32, 97, 256, 101, 114, 111, 116, 105, 99, 32, 108, 111, 118, 101, 114, 32, 97, 110, 100, 32, 97, 256, 97, 32, 112, 104, 101, 110, 111, 109, 101, 110, 111, 110, 32, 99, 97, 112, 97, 98, 108, 101, 32, 111, 102, 32, 105, 110, 115, 112, 105, 114, 105, 110, 103, 32, 99, 111, 117, 114, 97, 103, 101, 44, 32, 118, 97, 108, 111, 114, 44, 32, 103, 114, 101, 97, 116, 32, 100, 101, 101, 100, 256, 97, 110, 100, 32, 119, 111, 114, 107, 115, 44, 32, 97, 110, 100, 32, 118, 97, 110, 113, 117, 105, 115, 104, 105, 110, 103, 32, 109, 97, 110, 39, 256, 110, 97, 116, 117, 114, 97, 108, 32, 102, 101, 97, 114, 32, 111, 102, 32, 100, 101, 97, 116, 104, 46, 32, 73, 116, 32, 105, 256, 115, 101, 101, 110, 32, 97, 256, 116, 114, 97, 110, 115, 99, 101, 110, 100, 105, 110, 103, 32, 105, 116, 256, 101, 97, 114, 116, 104, 108, 121, 32, 111, 114, 105, 103, 105, 110, 256, 97, 110, 100, 32, 97, 116, 116, 97, 105, 110, 105, 110, 103, 32, 115, 112, 105, 114, 105, 116, 117, 97, 108, 32, 104, 101, 105, 103, 104, 116, 115, 46, 32, 84, 104, 101, 32, 101, 120, 116, 114, 97, 111, 114, 100, 105, 110, 97, 114, 121, 32, 101, 108, 101, 118, 97, 116, 105, 111, 110, 32, 111, 102, 32, 116, 104, 101, 32, 99, 111, 110, 99, 101, 112, 116, 32, 111, 102, 32, 108, 111, 118, 101, 32, 114, 97, 105, 115, 101, 256, 97, 32, 113, 117, 101, 115, 116, 105, 111, 110, 32, 111, 102, 32, 119, 104, 101, 116, 104, 101, 114, 32, 115, 111, 109, 101, 32, 111, 102, 32, 116, 104, 101, 32, 109, 111, 115, 116, 32, 101, 120, 116, 114, 101, 109, 101, 32, 101, 120, 116, 101, 110, 116, 256, 111, 102, 32, 109, 101, 97, 110, 105, 110, 103, 32, 109, 105, 103, 104, 116, 32, 98, 101, 32, 105, 110, 116, 101, 110, 100, 101, 100, 32, 97, 256, 104, 117, 109, 111, 114, 32, 111, 114, 32, 102, 97, 114, 99, 101, 46, 32, 69, 114, 111, 256, 105, 256, 97, 108, 109, 111, 115, 116, 32, 97, 108, 119, 97, 121, 256, 116, 114, 97, 110, 115, 108, 97, 116, 101, 100, 32, 97, 256, 34, 108, 111, 118, 101, 44, 34, 32, 97, 110, 100, 32, 116, 104, 101, 32, 69, 110, 103, 108, 105, 115, 104, 32, 119, 111, 114, 100, 32, 104, 97, 256, 105, 116, 256, 111, 119, 110, 32, 118, 97, 114, 105, 101, 116, 105, 101, 256, 97, 110, 100, 32, 97, 109, 98, 105, 103, 117, 105, 116, 105, 101, 256, 116, 104, 97, 116, 32, 112, 114, 111, 118, 105, 100, 101, 32, 97, 100, 100, 105, 116, 105, 111, 110, 97, 108, 32, 99, 104, 97, 108, 108, 101, 110, 103, 101, 256, 116, 111, 32, 116, 104, 101, 32, 101, 102, 102, 111, 114, 116, 32, 116, 111, 32, 117, 110, 100, 101, 114, 115, 116, 97, 110, 100, 32, 116, 104, 101, 32, 69, 114, 111, 256, 111, 102, 32, 97, 110, 99, 105, 101, 110, 116, 32, 65, 116, 104, 101, 110, 115, 46]\n",
            "594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the more we merge, the bigger the vocablary is, shorter sequences\\\n",
        "tune this to get the best vocabulary size (token size) \\\n"
      ],
      "metadata": {
        "id": "EqtGh8oHupOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 276 # the desired final vocab size : we preset\n",
        "num_merges = vocab_size - 256\n",
        "ids = list(tokens) # we dont destroy the original list\n",
        "\n",
        "merges = {} #(int1, int2) -> int3\n",
        "# merge dict is maintain child1(int1), child2(int2) maping to a new tokens(int3)\n",
        "i = 0\n",
        "while i <= num_merges:\n",
        "  stats = get_common_pair(ids)\n",
        "  top_pair = max(stats, key=stats.get)\n",
        "  idx = 256 + i\n",
        "  print(f\"merge pair {top_pair} into new id {idx}\")\n",
        "  ids = map_new_token_with_new_id(ids, top_pair, idx)\n",
        "  merges[top_pair] = idx\n",
        "  i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DLzMmc0WVz5",
        "outputId": "f77d8779-a112-4e8c-c5dc-185f1e4bce29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merge pair (115, 32) into new id 256\n",
            "merge pair (101, 32) into new id 257\n",
            "merge pair (97, 110) into new id 258\n",
            "merge pair (116, 104) into new id 259\n",
            "merge pair (100, 32) into new id 260\n",
            "merge pair (105, 110) into new id 261\n",
            "merge pair (101, 110) into new id 262\n",
            "merge pair (116, 32) into new id 263\n",
            "merge pair (111, 102) into new id 264\n",
            "merge pair (264, 32) into new id 265\n",
            "merge pair (111, 114) into new id 266\n",
            "merge pair (258, 260) into new id 267\n",
            "merge pair (97, 108) into new id 268\n",
            "merge pair (259, 257) into new id 269\n",
            "merge pair (97, 256) into new id 270\n",
            "merge pair (116, 105) into new id 271\n",
            "merge pair (110, 32) into new id 272\n",
            "merge pair (114, 111) into new id 273\n",
            "merge pair (261, 103) into new id 274\n",
            "merge pair (274, 32) into new id 275\n",
            "merge pair (97, 114) into new id 276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#statistic check\n",
        "print(\"ori tokens lenght:\", len(tokens))\n",
        "print(\"new tokens lenght:\", len(ids))\n",
        "print(f\"compression ratio: {len(tokens)/len(ids):.2f}X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dPg2HDzZd3U",
        "outputId": "5b216a5b-ea4a-454b-f5ed-287e8ce971ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ori tokens lenght: 617\n",
            "new tokens lenght: 436\n",
            "compression ratio: 1.42X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here come to the stage of **training** Tokenizer. \\\n",
        "we find the best size of vocabluary -> which will be store on Disk for later LLM use to learn \\\n",
        "we want to make sure it cover not just English \\\n",
        "and also code \\\n",
        "and maybe pixel in the future \\"
      ],
      "metadata": {
        "id": "lU7V07d0blj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoding\n",
        "Givem a sequence of integers in range [0, a], what are the text ?"
      ],
      "metadata": {
        "id": "D-urcMO_kR_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx: bytes([idx]) for idx in range(256)} # init the raw byte dictionary\n",
        "\n",
        "for (p0, p1), idx in merges.items():         # mapping for the new token id in 'merges' to the byte object\n",
        "  vocab[idx] = vocab[p0] + vocab[p1]\n",
        "  # print(vocab[idx])\n",
        "print('vocab: ', vocab)  # new extended vocab\n",
        "\n",
        "# def decode(ids:list, vocab:dict):\n",
        "#   '''\n",
        "#   decode the sequence of integers to human text\n",
        "#   using vocabulary that created before\n",
        "#   output: list of string\n",
        "#   '''\n",
        "#   decoded_list = []\n",
        "#   print('tokens:',ids)\n",
        "#   for i in range(len(ids)):\n",
        "#     token = vocab[ids[i]].decode(\"utf-8\", errors = 'replace')\n",
        "#     decoded_list.append(token)\n",
        "#   text = ''.join(decoded_list)\n",
        "#   return text\n",
        "\n",
        "def decode(ids:list):\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors = 'replace')\n",
        "  return text\n",
        "\n",
        "a = decode(ids)\n",
        "# b = decode2(ids)\n",
        "print('decoded output:',a)\n",
        "# print('decoded output:',b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MEG_nV58kRCo",
        "outputId": "333e3e99-06a2-4713-ffbd-3293892bf5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab:  {0: b'\\x00', 1: b'\\x01', 2: b'\\x02', 3: b'\\x03', 4: b'\\x04', 5: b'\\x05', 6: b'\\x06', 7: b'\\x07', 8: b'\\x08', 9: b'\\t', 10: b'\\n', 11: b'\\x0b', 12: b'\\x0c', 13: b'\\r', 14: b'\\x0e', 15: b'\\x0f', 16: b'\\x10', 17: b'\\x11', 18: b'\\x12', 19: b'\\x13', 20: b'\\x14', 21: b'\\x15', 22: b'\\x16', 23: b'\\x17', 24: b'\\x18', 25: b'\\x19', 26: b'\\x1a', 27: b'\\x1b', 28: b'\\x1c', 29: b'\\x1d', 30: b'\\x1e', 31: b'\\x1f', 32: b' ', 33: b'!', 34: b'\"', 35: b'#', 36: b'$', 37: b'%', 38: b'&', 39: b\"'\", 40: b'(', 41: b')', 42: b'*', 43: b'+', 44: b',', 45: b'-', 46: b'.', 47: b'/', 48: b'0', 49: b'1', 50: b'2', 51: b'3', 52: b'4', 53: b'5', 54: b'6', 55: b'7', 56: b'8', 57: b'9', 58: b':', 59: b';', 60: b'<', 61: b'=', 62: b'>', 63: b'?', 64: b'@', 65: b'A', 66: b'B', 67: b'C', 68: b'D', 69: b'E', 70: b'F', 71: b'G', 72: b'H', 73: b'I', 74: b'J', 75: b'K', 76: b'L', 77: b'M', 78: b'N', 79: b'O', 80: b'P', 81: b'Q', 82: b'R', 83: b'S', 84: b'T', 85: b'U', 86: b'V', 87: b'W', 88: b'X', 89: b'Y', 90: b'Z', 91: b'[', 92: b'\\\\', 93: b']', 94: b'^', 95: b'_', 96: b'`', 97: b'a', 98: b'b', 99: b'c', 100: b'd', 101: b'e', 102: b'f', 103: b'g', 104: b'h', 105: b'i', 106: b'j', 107: b'k', 108: b'l', 109: b'm', 110: b'n', 111: b'o', 112: b'p', 113: b'q', 114: b'r', 115: b's', 116: b't', 117: b'u', 118: b'v', 119: b'w', 120: b'x', 121: b'y', 122: b'z', 123: b'{', 124: b'|', 125: b'}', 126: b'~', 127: b'\\x7f', 128: b'\\x80', 129: b'\\x81', 130: b'\\x82', 131: b'\\x83', 132: b'\\x84', 133: b'\\x85', 134: b'\\x86', 135: b'\\x87', 136: b'\\x88', 137: b'\\x89', 138: b'\\x8a', 139: b'\\x8b', 140: b'\\x8c', 141: b'\\x8d', 142: b'\\x8e', 143: b'\\x8f', 144: b'\\x90', 145: b'\\x91', 146: b'\\x92', 147: b'\\x93', 148: b'\\x94', 149: b'\\x95', 150: b'\\x96', 151: b'\\x97', 152: b'\\x98', 153: b'\\x99', 154: b'\\x9a', 155: b'\\x9b', 156: b'\\x9c', 157: b'\\x9d', 158: b'\\x9e', 159: b'\\x9f', 160: b'\\xa0', 161: b'\\xa1', 162: b'\\xa2', 163: b'\\xa3', 164: b'\\xa4', 165: b'\\xa5', 166: b'\\xa6', 167: b'\\xa7', 168: b'\\xa8', 169: b'\\xa9', 170: b'\\xaa', 171: b'\\xab', 172: b'\\xac', 173: b'\\xad', 174: b'\\xae', 175: b'\\xaf', 176: b'\\xb0', 177: b'\\xb1', 178: b'\\xb2', 179: b'\\xb3', 180: b'\\xb4', 181: b'\\xb5', 182: b'\\xb6', 183: b'\\xb7', 184: b'\\xb8', 185: b'\\xb9', 186: b'\\xba', 187: b'\\xbb', 188: b'\\xbc', 189: b'\\xbd', 190: b'\\xbe', 191: b'\\xbf', 192: b'\\xc0', 193: b'\\xc1', 194: b'\\xc2', 195: b'\\xc3', 196: b'\\xc4', 197: b'\\xc5', 198: b'\\xc6', 199: b'\\xc7', 200: b'\\xc8', 201: b'\\xc9', 202: b'\\xca', 203: b'\\xcb', 204: b'\\xcc', 205: b'\\xcd', 206: b'\\xce', 207: b'\\xcf', 208: b'\\xd0', 209: b'\\xd1', 210: b'\\xd2', 211: b'\\xd3', 212: b'\\xd4', 213: b'\\xd5', 214: b'\\xd6', 215: b'\\xd7', 216: b'\\xd8', 217: b'\\xd9', 218: b'\\xda', 219: b'\\xdb', 220: b'\\xdc', 221: b'\\xdd', 222: b'\\xde', 223: b'\\xdf', 224: b'\\xe0', 225: b'\\xe1', 226: b'\\xe2', 227: b'\\xe3', 228: b'\\xe4', 229: b'\\xe5', 230: b'\\xe6', 231: b'\\xe7', 232: b'\\xe8', 233: b'\\xe9', 234: b'\\xea', 235: b'\\xeb', 236: b'\\xec', 237: b'\\xed', 238: b'\\xee', 239: b'\\xef', 240: b'\\xf0', 241: b'\\xf1', 242: b'\\xf2', 243: b'\\xf3', 244: b'\\xf4', 245: b'\\xf5', 246: b'\\xf6', 247: b'\\xf7', 248: b'\\xf8', 249: b'\\xf9', 250: b'\\xfa', 251: b'\\xfb', 252: b'\\xfc', 253: b'\\xfd', 254: b'\\xfe', 255: b'\\xff', 256: b's ', 257: b'e ', 258: b'an', 259: b'th', 260: b'd ', 261: b'in', 262: b'en', 263: b't ', 264: b'of', 265: b'of ', 266: b'or', 267: b'and ', 268: b'al', 269: b'the ', 270: b'as ', 271: b'ti', 272: b'n ', 273: b'ro', 274: b'ing', 275: b'ing ', 276: b'ar'}\n",
            "decoded output: In the Symposium, Eros is recognized both as erotic lover and as a phenomenon capable of inspiring courage, valor, great deeds and works, and vanquishing man's natural fear of death. It is seen as transcending its earthly origins and attaining spiritual heights. The extraordinary elevation of the concept of love raises a question of whether some of the most extreme extents of meaning might be intended as humor or farce. Eros is almost always translated as \"love,\" and the English word has its own varieties and ambiguities that provide additional challenges to the effort to understand the Eros of ancient Athens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text:str):\n",
        "  '''\n",
        "  encode the human text to sequence of integers\n",
        "  integer is map to byte object, from vocabulary\n",
        "  output: list of integers\n",
        "  '''\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = get_common_pair(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float('inf')))\n",
        "    if pair not in merges:\n",
        "      break\n",
        "      print('Nothing else can be merge!')\n",
        "    idx = merges[pair]\n",
        "    tokens = map_new_token_with_new_id(tokens, pair, idx)\n",
        "  return tokens\n",
        "a = encode(text)\n",
        "print(len(a))\n",
        "encode('Hello worlds!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoRbfqCH3uVI",
        "outputId": "b3845f88-56ae-4a65-c4f0-39183ad79b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[72, 101, 108, 108, 111, 32, 119, 266, 108, 100, 115, 33]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(encode('Hello worlds!')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KaDM9Wh_OHl",
        "outputId": "69ec4adf-efc8-4cef-e96b-edd769053760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello worlds!\n"
          ]
        }
      ]
    }
  ]
}